{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43cbc574",
   "metadata": {},
   "source": [
    "# Project 3b\n",
    "\n",
    "The final part of the project will ask you to perform your own data science project to classify a new dataset.\n",
    "\n",
    "## Submission Details\n",
    "\n",
    "**Project is due June 14th at 11:59 pm (Friday Midnight). To submit the project, please save the notebook\n",
    "as a pdf file and submit the assignment via Gradescope. In addition, make sure that\n",
    "all figures are legible and suï¬€iciently large. For best pdf results, we recommend printing the notebook using [$\\LaTeX$](https://www.latex-project.org/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59b8b12",
   "metadata": {},
   "source": [
    "## Loading Essentials and Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "id": "40f8731d",
   "metadata": {},
   "source": [
    "# fix for windows memory leak with MKL\n",
    "import os\n",
    "import platform\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"2\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d48374c",
   "metadata": {},
   "source": [
    "# import libraries\n",
    "import time\n",
    "import random\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt  # this is used for the plot the graph\n",
    "\n",
    "# Sklearn classes\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    ")\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, silhouette_score\n",
    "import sklearn.metrics.cluster as smc\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    LabelEncoder,\n",
    "    MinMaxScaler,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn import tree\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "import seaborn as sns\n",
    "from helper import (\n",
    "    draw_confusion_matrix,\n",
    "    heatmap,\n",
    "    make_meshgrid,\n",
    "    plot_contours,\n",
    "    draw_contour,\n",
    ")\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Sets random seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e2b27da2",
   "metadata": {},
   "source": [
    "# (100 pts) Putting it all together: Classify your own data\n",
    "\n",
    "Through the course of this program, you have acquired knowledge and skills in applying various models to tackle supervised learning tasks. Now, we challenge you to harness your cumulative learning and create a model capable of predicting whether a hotel reservation will be canceled or not.\n",
    "\n",
    "### Context\n",
    "Hotels welcome millions of guests every year, and their primary objective is to keep rooms occupied and paid for. Cancellations can be detrimental to the business, as it may become challenging to rebook a room on short notice. Consequently, it is beneficial for hotels to anticipate which reservations are likely to be canceled. The provided dataset offers a diverse range of information about bookings, which you will utilize to predict cancellations.\n",
    "\n",
    "### Challenge\n",
    "The goal of this project is to develop a predictive model that can determine whether a reservation will be canceled based on the available input parameters.\n",
    "\n",
    "While we will provide specific instructions to guide you in the right direction, you have the freedom to choose the models and preprocessing techniques that you deem most appropriate. Upon completion, we request that you provide a detailed description outlining the models you selected and the rationale behind your choices.\n",
    "\n",
    "### Data Description\n",
    "Refer to https://www.kaggle.com/competitions/m-148-spring-2024-project-3/data for information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa9cfc",
   "metadata": {},
   "source": [
    "## (50 pts) Preprocessing\n",
    "For the dataset, the following are mandatory pre-processing steps for your data:\n",
    "\n",
    "- **Use One-Hot Encoding on all categorical features** (specify whether you keep the extra feature or not for features with multiple values)\n",
    "- Determine which fields need to be dropped\n",
    "- **Handle missing values** (Specify your strategy)\n",
    "- **Rescale the real valued features using any strategy you choose** (StandardScaler, MinMaxScaler, Normalizer, etc)\n",
    "- **Augment at least one feature**\n",
    "- **Implement a train-test split with 20% of the data going to the test data**. Make sure that the test and train data are balanced in terms of the desired class.\n",
    "\n",
    "After writing your preprocessing code, write out a description of what you did for each step and provide a justification for your choices. All descriptions should be written in the markdown cells of the jupyter notebook. Make sure your writing is clear and professional.  \n",
    "\n",
    "We highly recommend reading through the [scikit-learn documentation](https://scikit-learn.org/stable/data_transforms.html) to make this part easier."
   ]
  },
  {
   "cell_type": "code",
   "id": "4a4a7cea",
   "metadata": {},
   "source": [
    "# Loading in dataset\n",
    "df = pd.read_csv(\"datasets/hotel_booking.csv\")\n",
    "\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9eff87757c50a4e3",
   "metadata": {},
   "source": [
    "df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8950b1e77e714456",
   "metadata": {},
   "source": [
    "df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3e37ac8520da9ee7",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c444a14dd4c13",
   "metadata": {},
   "source": [
    "From reading the documentation, I found that the following columns are categorical and will be dealt wtih accordingly:\n",
    "* hotel\n",
    "* is_cancelled\n",
    "* arrival_date_month\n",
    "* meal\n",
    "* country\n",
    "* reserved_room_types\n",
    "* deposit_type\n",
    "* customer_type\n",
    "* name\n",
    "* email\n",
    "* phone_number\n",
    "\n",
    "<br>\n",
    "\n",
    "We can drop name, email, phone_number since these do not provide any useful information"
   ]
  },
  {
   "cell_type": "code",
   "id": "c14387998f2aca4f",
   "metadata": {},
   "source": [
    "df = df.drop(columns=['name', 'email', 'phone-number'])\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a91cccd00870eca9",
   "metadata": {},
   "source": [
    "# Checking for null values\n",
    "df.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3bf798684d603ce3",
   "metadata": {},
   "source": [
    "I found that there are only 3 null values in the 'children' section, and since the dataset is rather large with almost 70,000 entries, I'm going to just drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "id": "b4a0f49bfdd4244f",
   "metadata": {},
   "source": [
    "# Dropping na values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Checking to make sure it worked\n",
    "print(df.isnull().sum())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "647104ebe5d2e4a2",
   "metadata": {},
   "source": [
    "# Checking if data is balanced\n",
    "sns.countplot(x='is_canceled', data=df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4a007c296f0d4530",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "I decided I am going to create a new feature called 'is_family' based on 'children' and 'babies'. According to SHR Group's Hotel Industry Trend, families were the most likely to cancel in 2024, so this augmented feature should provide some good insight.\n",
    "\n",
    "I am also creating a column called 'stay_duration' which calculates the total number of nights a guest is staying, a column called 'is_repeated_guest' which indicates if a guest has stayed with the hotel before, a column 'has_special_requests' which just indicates if the guest has made special requests, and 'is_high_season' which indicates if a booking is made during a high travel season (usually in the summer), and a column called 'cancellation_rate' which calculates the rate of cancellations for a customer."
   ]
  },
  {
   "cell_type": "code",
   "id": "dc0d1e5d24e77f1b",
   "metadata": {},
   "source": [
    "# # Creating new feature indicating if a booking is made for a family\n",
    "df['is_family'] = df.apply(lambda row: 1 if row['children'] > 0 or row['babies'] > 0 else 0, axis=1)\n",
    "\n",
    "# Stay Duration\n",
    "df['stay_duration'] = df['stays_in_weekend_nights'] + df['stays_in_week_nights']\n",
    "\n",
    "# Cancellation rate for each booking\n",
    "df['cancellation_rate'] = df['previous_cancellations'] / (df['previous_cancellations'] + df['previous_bookings_not_canceled'])\n",
    "# Fill any NaN values which might occur due to division by zero\n",
    "# This occurs when there's a new guest\n",
    "df['cancellation_rate'].fillna(0, inplace=True)\n",
    "\n",
    "df['is_repeated_guest'] = np.where((df['previous_cancellations'] > 0) | (df['previous_bookings_not_canceled'] > 0), 1, 0)\n",
    "\n",
    "df['has_special_request'] = np.where(df['total_of_special_requests'] > 0, 1, 0)\n",
    "\n",
    "df['is_high_season'] = df['arrival_date_month'].apply(lambda x: 1 if x in ['June', 'July', 'August'] else 0)\n",
    "\n",
    "\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "636689c20d0ff298",
   "metadata": {},
   "source": [
    "# Splitting features into numerical and categorical\n",
    "numerical = ['stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'previous_cancellations', 'previous_bookings_not_canceled', 'booking_changes', 'days_in_waiting_list', 'adr', 'required_car_parking_spaces', 'stay_duration', 'cancellation_rate']\n",
    "\n",
    "categorical = ['hotel', 'arrival_date_month', 'meal', 'country', 'reserved_room_type', 'deposit_type', 'customer_type', 'is_high_season', 'is_repeated_guest', 'has_special_request','is_family']\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "19beddfb5385e35",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Now I am just going to do some basic exploratory data analysis to look at distributions\n",
    "\n",
    "I suspect there will be a strong relationship between customer_type and cancellations"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d717aed36251303",
   "metadata": {},
   "source": [
    "# Checking correlation between customer_type and cancellations\n",
    "contingency_table = pd.crosstab(df['customer_type'], df['is_canceled'])\n",
    "print(contingency_table)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56bfc4499519beb1",
   "metadata": {},
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2, p, dof, ex = chi2_contingency(contingency_table)\n",
    "print(\"p-value of chi-square test:\", p)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c9a6f26d01f214b6",
   "metadata": {},
   "source": [
    "It looks like there is a very strong association. This makes sense as those travelling in groups are less likely to cancel than those travelling alone or as a couple. This will be an important feature in the model."
   ]
  },
  {
   "cell_type": "code",
   "id": "4007da3002162067",
   "metadata": {},
   "source": [
    "# Creating a bar graph for showing number of bookings per hotel\n",
    "\n",
    "sns.countplot(x='hotel', data=df)\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='customer_type', data=df)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f1710cdd827995a",
   "metadata": {},
   "source": [
    "# Looking at relationship between is_family and cancellations\n",
    "pd.crosstab(df['is_family'], df['is_canceled']).plot(kind='bar', stacked=True)\n",
    "plt.xlabel('Is Family')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b298e40eddd35998",
   "metadata": {},
   "source": [
    "df.hist(figsize=(20,20))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67e975241874a792",
   "metadata": {},
   "source": [
    "# Looking at relationship between average daily rate and cancellations\n",
    "sns.boxplot(x='is_canceled', y='adr', data=df)\n",
    "plt.xlabel('Is Canceled')\n",
    "plt.ylabel('Average Daily Rate')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1171d58601454f02",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "id": "f8d254cdde4727",
   "metadata": {},
   "source": [
    "# Defining target\n",
    "y = df['is_canceled']\n",
    "\n",
    "# Define features\n",
    "X = df.drop(columns='is_canceled')\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e66fb73b629e8c9f",
   "metadata": {},
   "source": [
    "# Creating pipeline for transforming features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical),\n",
    "        ('cat', categorical_transformer, categorical)\n",
    "    ])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df3a1ee99acfe1d7",
   "metadata": {},
   "source": [
    "train = preprocessor.fit_transform(X_train)\n",
    "test = preprocessor.transform(X_test)\n",
    "\n",
    "# Getting feature names\n",
    "feature_names = preprocessor.get_feature_names_out(list(X.columns))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c7bfae163e4156a",
   "metadata": {},
   "source": [
    "I ended up keeping the extra features after one-hot encoding as I didn't see a reason to not include them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9a682",
   "metadata": {},
   "source": [
    "\n",
    "## (50 pts) Try out a few models\n",
    "Now that you have pre-processed your data, you are ready to try out different models. \n",
    "\n",
    "For this part of the project, we want you to experiment with all the different models demonstrated in the course to determine which one performs best on the dataset.\n",
    "\n",
    "You must perform classification using at least 3 of the following models:\n",
    "- Logistic Regression\n",
    "- K-nearest neighbors\n",
    "- SVM\n",
    "- Decision Tree\n",
    "- Multi-Layer Perceptron\n",
    "\n",
    "Due to the size of the dataset, be careful which models you use and look at their documentation to see how you should tackle this size issue for each model.\n",
    "\n",
    "For full credit, you must perform some hyperparameter optimization on your models of choice. You may find the following scikit-learn library on [hyperparameter optimization](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) useful.\n",
    "\n",
    "For each model chosen, write a description of which models were chosen, which parameters you optimized, and which parameters you choose for your best model. \n",
    "While the previous part of the project asked you to pre-process the data in a specific manner, you may alter pre-processing step as you wish to adjust for your chosen classification models.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "da5dfd39631b487b",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization for KNN model\n",
    "# Define the parameter grid\n",
    "params = {\n",
    "    'n_neighbors' : [1, 3, 5, 7, 9],\n",
    "    'metric' : [\"euclidean\", \"manhattan\"]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_knn = HalvingGridSearchCV(estimator=KNeighborsClassifier(), param_grid=params, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_knn.fit(train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search_knn.best_params_)\n",
    "print(\"Best Score: \", grid_search_knn.best_score_)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4c3bc8f7376d43ee",
   "metadata": {},
   "source": [
    "# Using fitted model to make predictions\n",
    "test_predictions_knn = grid_search_knn.best_estimator_.predict(test)\n",
    "\n",
    "# Calculate the accuracy of the model on the test data\n",
    "test_accuracy = accuracy_score(y_test, test_predictions_knn)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test Accuracy (KNN): {test_accuracy*100:.3f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(metrics.classification_report(y_test, test_predictions_knn))\n",
    "\n",
    "draw_confusion_matrix(y_test, test_predictions_knn, ['Not Cancelled', 'Cancelled'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e01ed1a74a871d41",
   "metadata": {},
   "source": [
    "with 'has_special_requests' -> 83.2\n",
    "without ->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a16d49167c14dd",
   "metadata": {},
   "source": [
    "## KNN Model Description\n",
    "\n",
    "This KNN model is pretty accurate, with a test accuracy of 83%. I optimized the hyperparameters using GridSearchCV and found the best parameters to be {'metric': 'euclidean', 'n_neighbors': 9}. It trains very quickly which is I used GridSearchCV instead of HalvingGridSearchCV, which I use in later models."
   ]
  },
  {
   "cell_type": "code",
   "id": "cb3b970f294242b6",
   "metadata": {},
   "source": [
    "# Building Logistic Regression model and hyperparameter optimizing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "params = {\n",
    "    'penalty': [\"l1\", \"l2\"],\n",
    "    'solver': [\"liblinear\", \"saga\"],\n",
    "    'C': [0.001, 0.1, 10]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_log = HalvingGridSearchCV(estimator=logreg, param_grid=params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_log.fit(train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search_log.best_params_)\n",
    "print(\"Best Score: \", grid_search_log.best_score_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e578cb5512bbbd6b",
   "metadata": {},
   "source": [
    "# Testing best logistic regression model\n",
    "best_logreg_model = grid_search_log.best_estimator_\n",
    "\n",
    "test_predictions_logreg = best_logreg_model.predict(test)\n",
    "\n",
    "test_accuracy_logreg = accuracy_score(y_test, test_predictions_logreg)\n",
    "\n",
    "print(f\"Test Accuracy (Logistic Regression): {test_accuracy_logreg*100:.3f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(metrics.classification_report(y_test, test_predictions_logreg))\n",
    "\n",
    "draw_confusion_matrix(y_test, test_predictions_logreg, ['Not Cancelled', 'Cancelled'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "21814f27286f1be8",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Description\n",
    "\n",
    "This logistic regression model is surprisingly less accurate than a KNN model, with a max test accuracy at 80%. The best parameters were {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}. It also is very slow to train compared to other models, even with HalvingGridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "id": "fa5415983e10ee74",
   "metadata": {},
   "source": [
    "# Building decision tree model\n",
    "\n",
    "# Optimizing\n",
    "params = {\n",
    "    'max_depth': [10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "grid_search_tree = HalvingGridSearchCV(estimator=tree, param_grid=params, cv=10, n_jobs=-1)\n",
    "\n",
    "# Fitting GridSearch\n",
    "grid_result_tree = grid_search_tree.fit(train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters found: \", grid_result_tree.best_params_)\n",
    "print(\"Highest accuracy: \", grid_result_tree.best_score_)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "37bd2ce8cbd54f49",
   "metadata": {},
   "source": [
    "# Testing best decision tree model\n",
    "best_tree_model = grid_search_tree.best_estimator_\n",
    "\n",
    "test_predictions_tree = best_tree_model.predict(test)\n",
    "\n",
    "test_accuracy_tree = accuracy_score(y_test, test_predictions_tree)\n",
    "\n",
    "print(f\"Test Accuracy (Decision Tree): {test_accuracy_tree*100:.3f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(metrics.classification_report(y_test, test_predictions_tree))\n",
    "\n",
    "draw_confusion_matrix(y_test, test_predictions_tree, ['Not Cancelled', 'Cancelled'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "19bc6129b9c11d07",
   "metadata": {},
   "source": [
    "## Decision Tree Model Description\n",
    "\n",
    "This Decision Tree model is around the same accuracy as the best KNN model, with an accuracy of 82%. The best parameters were {'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10}."
   ]
  },
  {
   "cell_type": "code",
   "id": "16e1d0459fbc5d16",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Define the parameters // refined\n",
    "params = {\n",
    "    'bootstrap': [False],\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [45, 50, 55],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'n_estimators': [450, 500, 550]\n",
    "}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid_search_rf = HalvingGridSearchCV(estimator=rf,param_grid=params, cv=10, n_jobs=-1)\n",
    "\n",
    "# Run the grid search\n",
    "grid_search_rf.fit(train, y_train)\n",
    "\n",
    "# Print out the best parameters\n",
    "print(\"Best parameters found: \", grid_search_rf.best_params_)\n",
    "print(\"Highest accuracy found: \", grid_search_rf.best_score_)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d718b04b81666d4d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Testing the best Random Forest model\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "# Predict on the testing data\n",
    "test_predictions_rf = best_rf_model.predict(test)\n",
    "\n",
    "# Get the accuracy of the model\n",
    "test_accuracy_rf = accuracy_score(y_test, test_predictions_rf)\n",
    "\n",
    "print(f\"Test Accuracy (Random Forest): {test_accuracy_rf * 100:.3f}\")\n",
    "\n",
    "# Check the classification report\n",
    "print(metrics.classification_report(y_test, test_predictions_rf))\n",
    "\n",
    "# Predict probabilities\n",
    "probabilities_rf = best_rf_model.predict_proba(test)\n",
    "\n",
    "# Probabilities for positive class\n",
    "auc = roc_auc_score(y_test, probabilities_rf[:, 1])\n",
    "\n",
    "print(f\"AUC-ROC score for Random Forest is {auc}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "draw_confusion_matrix(y_test, test_predictions_rf, ['Not Cancelled', 'Cancelled'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1669a323d91eb997",
   "metadata": {},
   "source": [
    "## Random Forest Model Description\n",
    "\n",
    "This Random Forest Classifier was the best model, achieving a test accuracy of 86% and an AUC-ROC score of nearly 94%. The best parameters for it were: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 45, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 550}\n",
    "Highest accuracy found:  0.8559285291760205. This one was a little slow to train, so to maximize efficiency I used HalvingGridSearchCV which greatly reduces the time to train without affecting the model's performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb7d356",
   "metadata": {},
   "source": [
    "## Extra Credit \n",
    "\n",
    "We have provided an extra test dataset named `hotel_booking_test.csv` that does not have the target labels. Classify the samples in the dataset with any method of your choosing and save the predictions into a csv file. Submit the file to our [Kaggle](https://www.kaggle.com/competitions/m-148-spring-2024-project-3/) contest. The website will specify your classification accuracy on the test set. We will award a bonus point for the project for every percentage point over 75% that you get on your kaggle test accuracy.\n",
    "\n",
    "To get the bonus points, you must also write out a summary of the model that you submit including any changes you made to the pre-processing steps. The summary must be written in a markdown cell of the jupyter notebook. Note that you should not change earlier parts of the project to complete the extra credit.\n",
    "\n",
    "**Please refer to *Submission and evaluation* section on the contest page for the `csv` file formatting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe8f48b",
   "metadata": {},
   "source": [
    "### Summary\n",
    "The model I chose to submit is the best bagging classifier model, with parameters Best parameters found:  {'bootstrap': False, 'bootstrap_features': True, 'estimator': DecisionTreeClassifier(random_state=42), 'max_features': 0.7, 'max_samples': 0.7, 'n_estimators': 300}. It ended up having an 86% test accuracy.\n",
    "\n",
    "One thing I noticed in the above parts, was that class 1 (cancelled) was a little underrepresented in the dataset. In the classification reports, class 1 was consistently recalled worse by every model trained. As a result, I used SMOTE (Synthetic Minority Oversampling Technique), which synthetically creates more sample in the minority class so that the classes are balanced. This improved my accuracy a little bit, but also helped improve the models' ability to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6ca084a167440",
   "metadata": {},
   "source": [
    "# Cleaning and processing the testing data"
   ]
  },
  {
   "cell_type": "code",
   "id": "4b4d408b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Read in hotel_booking_test\n",
    "hotel = pd.read_csv(\"datasets/hotel_booking_test.csv\")\n",
    "\n",
    "hotel.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c102272d88d1815",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "hotel.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b524a6dbb347a9d9",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Applying same preprocessing steps as before\n",
    "hotel['is_family'] = hotel.apply(lambda row: 1 if row['children'] > 0 or row['babies'] > 0 else 0, axis=1)\n",
    "\n",
    "# Stay Duration\n",
    "hotel['stay_duration'] = hotel['stays_in_weekend_nights'] + hotel['stays_in_week_nights']\n",
    "\n",
    "hotel['is_repeated_guest'] = np.where((hotel['previous_cancellations'] > 0) | (hotel['previous_bookings_not_canceled'] > 0), 1, 0)\n",
    "\n",
    "# Cancellation rate for each booking\n",
    "hotel['cancellation_rate'] = hotel['previous_cancellations'] / (hotel['previous_cancellations'] + hotel['previous_bookings_not_canceled'])\n",
    "# Fill any NaN values which might occur due to division by zero\n",
    "# This occurs when there's a new guest\n",
    "hotel['cancellation_rate'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "hotel['has_special_request'] = np.where(hotel['total_of_special_requests'] > 0, 1, 0)\n",
    "\n",
    "hotel['is_high_season'] = hotel['arrival_date_month'].apply(lambda x: 1 if x in ['June', 'July', 'August'] else 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b81e45ddf4e4f886",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Dropping email, name, phone numer\n",
    "hotel = hotel.drop(['email', 'name', 'phone-number'], axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "caba8cd57ebec11a",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Processing dataframe\n",
    "hotel_transformed = preprocessor.transform(hotel)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7f2bd409681e4405",
   "metadata": {},
   "source": [
    "# Changing the preprocessing of training dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "8314f4b8ce5fa544",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Run the preprocessors\n",
    "train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Getting the categorical transformer from the pipeline\n",
    "categorical_transformer = preprocessor.named_transformers_['cat']\n",
    "\n",
    "# Get the trained OneHotEncoder from the categorical transformer\n",
    "onehot = categorical_transformer.named_steps['onehot']\n",
    "\n",
    "# Get the categories from the encoder\n",
    "transformed_categories = onehot.categories_\n",
    "\n",
    "# Create feature names for the transformed categories\n",
    "cat_features_transformed = [f\"{feat}_{val}\" for feat, vals in zip(categorical, transformed_categories) for val in vals]\n",
    "\n",
    "# Combine all feature names\n",
    "feature_names = numerical + cat_features_transformed\n",
    "\n",
    "\n",
    "\n",
    "# Now for applying SMOTE\n",
    "smote = SMOTE(random_state=2)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(train_preprocessed, y_train)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "de88b9ec854362",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a5f383682712a34",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Hyperparameter optimization for KNN model\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "# Define the parameter grid\n",
    "params = {\n",
    "    'n_neighbors' : [1, 3, 5, 7, 9],\n",
    "    'metric' : [\"euclidean\", \"manhattan\"]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_knn = HalvingRandomSearchCV(estimator=KNeighborsClassifier(), param_grid=params, cv=10, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters: \", grid_search_knn.best_params_)\n",
    "print(\"Best Score: \", grid_search_knn.best_score_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8716b73343ba20c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Using fitted model to make predictions\n",
    "test_predictions_knn = grid_search_knn.best_estimator_.predict(test)\n",
    "\n",
    "# Calculate the accuracy of the model on the test data\n",
    "test_accuracy = accuracy_score(y_test, test_predictions_knn)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test Accuracy (KNN): {test_accuracy*100:.3f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(metrics.classification_report(y_test, test_predictions_knn))\n",
    "\n",
    "draw_confusion_matrix(y_test, test_predictions_knn, ['Not Cancelled', 'Cancelled'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e0e5f90fd16219e8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Define the parameters // refined\n",
    "params = {\n",
    "    'n_estimators': [500, 525, 550, 575, 600],  # Adjusted around 550\n",
    "    'criterion': ['gini', 'entropy'],  # Keeping 'entropy' as a search option\n",
    "    'max_depth': [45, 50, 55, 60],  # Adjusted around 50\n",
    "    'min_samples_split': [2, 3, 4, 5],  # Adjusted around 3\n",
    "    'min_samples_leaf': [1, 2, 3],  # Adjusted around 2\n",
    "    'bootstrap': [False],  # Keeping 'False' as per your best results\n",
    "    'max_features': ['sqrt', 'log2', None]  # Adding some more options around 'sqrt'   \n",
    "}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid_search_rf = HalvingRandomSearchCV(estimator=rf,param_grid=params, cv=10, n_jobs=-1)\n",
    "\n",
    "# Run the grid search\n",
    "grid_search_rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print out the best parameters\n",
    "print(\"Best parameters found: \", grid_search_rf.best_params_)\n",
    "print(\"Highest accuracy found: \", grid_search_rf.best_score_)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "638fc9187fa2c416",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Testing the best Random Forest model\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "# Predict on the testing data\n",
    "test_predictions_rf = best_rf_model.predict(test)\n",
    "\n",
    "# Get the accuracy of the model\n",
    "test_accuracy_rf = accuracy_score(y_test, test_predictions_rf)\n",
    "\n",
    "print(f\"Test Accuracy (Random Forest): {test_accuracy_rf * 100:.3f}\")\n",
    "\n",
    "# Check the classification report\n",
    "print(metrics.classification_report(y_test, test_predictions_rf))\n",
    "\n",
    "# Predict probabilities\n",
    "probabilities_rf = best_rf_model.predict_proba(test)\n",
    "\n",
    "# Probabilities for positive class\n",
    "auc = roc_auc_score(y_test, probabilities_rf[:, 1])\n",
    "\n",
    "print(f\"AUC-ROC score for Random Forest is {auc}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "draw_confusion_matrix(y_test, test_predictions_rf, ['Not Cancelled', 'Cancelled'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d2e127b9a352264a",
   "metadata": {},
   "source": [
    "Best parameters found:  {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 550}\n",
    "\n",
    "\n",
    "Test Accuracy (Random Forest): 85.731\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.91      0.88      8333\n",
    "           1       0.85      0.78      0.81      5585\n",
    "\n",
    "    accuracy                           0.86     13918\n",
    "   macro avg       0.86      0.84      0.85     13918\n",
    "weighted avg       0.86      0.86      0.86     13918\n",
    "\n",
    "AUC-ROC score for Random Forest is 0.9336623241115858\n",
    "\n",
    "<Figure size 640x480 with 2 Axes>"
   ]
  },
  {
   "cell_type": "code",
   "id": "ef8f27fb4a2341f1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# making bagging classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# make baseline model\n",
    "base_estimator_1 = DecisionTreeClassifier(random_state=SEED)\n",
    "# parameters // refined\n",
    "params = {\n",
    "    'n_estimators': [200, 250, 300, 350, 400],  # narrowed around 300\n",
    "    'max_samples': [0.6, 0.65, 0.7, 0.75, 0.8],  # narrowed around 0.7   \n",
    "    'max_features': [0.6, 0.65, 0.7, 0.75, 0.8],  # narrowed around 0.7\n",
    "    'bootstrap': [False],\n",
    "    'bootstrap_features': [True, False],  # Adding False as an option\n",
    "    'estimator': [base_estimator_1]\n",
    "    # Keeping the DecisionTreeClassifier since it has been found best \n",
    "}\n",
    "\n",
    "bag_clf = BaggingClassifier(random_state=SEED)\n",
    "\n",
    "hgs_bag = HalvingRandomSearchCV(bag_clf, params, scoring='accuracy', cv=10, n_jobs=-1)\n",
    "\n",
    "# train model\n",
    "hgs_bag.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# print best parameters and score\n",
    "print(\"Best parameters found: \", hgs_bag.best_params_)\n",
    "print(\"Highest accuracy found: \", hgs_bag.best_score_)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7271e92eadc21035",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "best_bagging_model = hgs_bag.best_estimator_\n",
    "\n",
    "test_predictions = best_bagging_model.predict(test)\n",
    "\n",
    "# Get the accuracy of the model\n",
    "test_accuracy = metrics.accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.3f}\")\n",
    "\n",
    "# Check the classification report\n",
    "print(metrics.classification_report(y_test, test_predictions))\n",
    "\n",
    "# Probabilities for positive class\n",
    "probabilities = best_bagging_model.predict_proba(test)\n",
    "auc = roc_auc_score(y_test, probabilities[:, 1])\n",
    "\n",
    "print(f\"AUC-ROC score is {auc}\")\n",
    "\n",
    "draw_confusion_matrix(y_test, test_predictions,\n",
    "                      ['Not Cancelled', 'Cancelled'])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7a156d4a7799ba91",
   "metadata": {},
   "source": [
    "Best parameters found:  {'bootstrap': False, 'bootstrap_features': True, 'estimator': DecisionTreeClassifier(random_state=42), 'max_features': 0.7, 'max_samples': 0.7, 'n_estimators': 300}\n",
    "\n",
    "\n",
    "Test Accuracy: 86.636\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.94      0.89      8333\n",
    "           1       0.90      0.76      0.82      5585\n",
    "\n",
    "    accuracy                           0.87     13918\n",
    "   macro avg       0.87      0.85      0.86     13918\n",
    "weighted avg       0.87      0.87      0.86     13918\n",
    "\n",
    "AUC-ROC score is 0.9367644643117864\n",
    "\n",
    "<Figure size 640x480 with 2 Axes>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The above two models weren't executed as they took too long after I tried expanding the parameter search and had to interrupt the kernel while executing, but I copied the outputs previously and put them into a markdown cell. ",
   "id": "3f6acdfab6a66a31"
  },
  {
   "cell_type": "markdown",
   "id": "c09c99136d5ee978",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "id": "9530650ffeefd21",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Predictions using best random forest model\n",
    "test_predictions_rf = best_rf_model.predict(hotel_transformed)\n",
    "\n",
    "# Convert the prediction array into a dataframe with 'target' column\n",
    "predictions_df = pd.DataFrame(test_predictions_rf, columns=['target'])\n",
    "\n",
    "# Create 'index' column that contains the row number from 0 to len(test_predictions)\n",
    "predictions_df['index'] = range(len(test_predictions_rf))\n",
    "\n",
    "# Reorder the columns so 'index' is first\n",
    "predictions_df = predictions_df[['index', 'target']]\n",
    "\n",
    "# Save the data frame to a .csv file without index column\n",
    "predictions_df.to_csv('test_predictions.csv', index=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2dc241c7b69d351e",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Predictions using bagging classifier\n",
    "bagging_test_predictions = best_bagging_model.predict(hotel_transformed)\n",
    "\n",
    "# Convert to dataframe\n",
    "predictions_bagging_df = pd.DataFrame(bagging_test_predictions, columns=['target'])\n",
    "\n",
    "# Create 'index'\n",
    "predictions_bagging_df['index'] = range(len(bagging_test_predictions))\n",
    "\n",
    "# Save data\n",
    "predictions_bagging_df.to_csv('bagging_test_predictions.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46bb24745b151ef6",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "429px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
